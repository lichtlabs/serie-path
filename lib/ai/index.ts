import { createOpenAI, OpenAIProviderSettings } from "@ai-sdk/openai"
import { createOllama, OllamaProviderSettings } from "ollama-ai-provider"

export const SUPPORTED_PROVIDERS = {
    openai: {
        models: [
            "gpt-4.1",
            "gpt-4.1-2025-04-14",
            "gpt-4.1-mini",
            "gpt-4.1-mini-2025-04-14",
            "gpt-4.1-nano",
            "gpt-4.1-nano-2025-04-14",
            "gpt-4o",
            "gpt-4o-2024-05-13",
            "gpt-4o-2024-08-06",
            "gpt-4o-2024-11-20",
            "gpt-4o-audio-preview",
            "gpt-4o-audio-preview-2024-10-01",
            "gpt-4o-audio-preview-2024-12-17",
            "gpt-4o-search-preview",
            "gpt-4o-search-preview-2025-03-11",
            "gpt-4o-mini-search-preview",
            "gpt-4o-mini-search-preview-2025-03-11",
            "gpt-4o-mini",
            "gpt-4o-mini-2024-07-18",
            "gpt-4-turbo",
            "gpt-4-turbo-2024-04-09",
            "gpt-4-turbo-preview",
            "gpt-4-0125-preview",
            "gpt-4-1106-preview",
            "gpt-4",
            "gpt-4-0613",
            "gpt-4.5-preview",
            "gpt-4.5-preview-2025-02-27",
            "gpt-3.5-turbo-0125",
            "gpt-3.5-turbo",
            "gpt-3.5-turbo-1106",
            "chatgpt-4o-latest",
            "o1",
            "o1-2024-12-17",
            "o1-mini",
            "o1-mini-2024-09-12",
            "o1-preview",
            "o1-preview-2024-09-12",
            "o3-mini",
            "o3-mini-2025-01-31",
            "o3",
            "o3-2025-04-16",
            "o4-mini",
            "o4-mini-2025-04-16",
            "codex-mini-latest",
            "computer-use-preview",
        ],
        config: {
            // baseUrl: undefined,
            apiKey: undefined,
        },
    },
    ollama: {
        models: [
            "athene-v2",
            "athene-v2:72b",
            "aya-expanse",
            "aya-expanse:8b",
            "aya-expanse:32b",
            "codegemma",
            "codegemma:2b",
            "codegemma:7b",
            "codellama",
            "codellama:7b",
            "codellama:13b",
            "codellama:34b",
            "codellama:70b",
            "codellama:code",
            "codellama:python",
            "command-r",
            "command-r:35b",
            "command-r-plus",
            "command-r-plus:104b",
            "command-r7b",
            "command-r7b:7b",
            "deepseek-coder-v2",
            "deepseek-coder-v2:16b",
            "deepseek-coder-v2:236b",
            "deepseek-v3",
            "deepseek-v3:671b",
            "dolphin3",
            "dolphin3:8b",
            "exaone3.5",
            "exaone3.5:2.4b",
            "exaone3.5:7.8b",
            "exaone3.5:32b",
            "falcon2",
            "falcon2:11b",
            "falcon3",
            "falcon3:1b",
            "falcon3:3b",
            "falcon3:7b",
            "falcon3:10b",
            "firefunction-v2",
            "firefunction-v2:70b",
            "gemma",
            "gemma:2b",
            "gemma:7b",
            "gemma2",
            "gemma2:2b",
            "gemma2:9b",
            "gemma2:27b",
            "gemma3",
            "gemma3n",
            "granite3-dense",
            "granite3-dense:2b",
            "granite3-dense:8b",
            "granite3-guardian",
            "granite3-guardian:2b",
            "granite3-guardian:8b",
            "granite3-moe",
            "granite3-moe:1b",
            "granite3-moe:3b",
            "granite3.1-dense",
            "granite3.1-dense:2b",
            "granite3.1-dense:8b",
            "granite3.1-moe",
            "granite3.1-moe:1b",
            "granite3.1-moe:3b",
            "llama2",
            "llama2:7b",
            "llama2:13b",
            "llama2:70b",
            "llama3",
            "llama3:8b",
            "llama3:70b",
            "llama3-chatqa",
            "llama3-chatqa:8b",
            "llama3-chatqa:70b",
            "llama3-gradient",
            "llama3-gradient:8b",
            "llama3-gradient:70b",
            "llama3.1",
            "llama3.1:8b",
            "llama3.1:70b",
            "llama3.1:405b",
            "llama3.2",
            "llama3.2:1b",
            "llama3.2:3b",
            "llama3.2-vision",
            "llama3.2-vision:11b",
            "llama3.2-vision:90b",
            "llama3.3",
            "llama3.3:70b",
            "llama-guard3",
            "llama-guard3:1b",
            "llama-guard3:8b",
            "llava",
            "llava:7b",
            "llava:13b",
            "llava:34b",
            "llava-llama3",
            "llava-llama3:8b",
            "llava-phi3",
            "llava-phi3:3.8b",
            "marco-o1",
            "marco-o1:7b",
            "mistral",
            "mistral:7b",
            "mistral-large",
            "mistral-large:123b",
            "mistral-nemo",
            "mistral-nemo:12b",
            "mistral-small",
            "mistral-small:22b",
            "mixtral",
            "mixtral:8x7b",
            "mixtral:8x22b",
            "moondream",
            "moondream:1.8b",
            "openhermes",
            "openhermes:v2.5",
            "nemotron",
            "nemotron:70b",
            "nemotron-mini",
            "nemotron-mini:4b",
            "olmo",
            "olmo:7b",
            "olmo:13b",
            "opencoder",
            "opencoder:1.5b",
            "opencoder:8b",
            "phi3",
            "phi3:3.8b",
            "phi3:14b",
            "phi3.5",
            "phi3.5:3.8b",
            "phi4",
            "phi4:14b",
            "qwen",
            "qwen:7b",
            "qwen:14b",
            "qwen:32b",
            "qwen:72b",
            "qwen:110b",
            "qwen2",
            "qwen2:0.5b",
            "qwen2:1.5b",
            "qwen2:7b",
            "qwen2:72b",
            "qwen2.5",
            "qwen2.5:0.5b",
            "qwen2.5:1.5b",
            "qwen2.5:3b",
            "qwen2.5:7b",
            "qwen2.5:14b",
            "qwen2.5:32b",
            "qwen2.5:72b",
            "qwen2.5-coder",
            "qwen2.5-coder:0.5b",
            "qwen2.5-coder:1.5b",
            "qwen2.5-coder:3b",
            "qwen2.5-coder:7b",
            "qwen2.5-coder:14b",
            "qwen2.5-coder:32b",
            "qwq",
            "qwq:32b",
            "sailor2",
            "sailor2:1b",
            "sailor2:8b",
            "sailor2:20b",
            "shieldgemma",
            "shieldgemma:2b",
            "shieldgemma:9b",
            "shieldgemma:27b",
            "smallthinker",
            "smallthinker:3b",
            "smollm",
            "smollm:135m",
            "smollm:360m",
            "smollm:1.7b",
            "tinyllama",
            "tinyllama:1.1b",
            "tulu3",
            "tulu3:8b",
            "tulu3:70b",
        ],
        config: {
            baseURL: "http://localhost:11434",
        },
    },
}

type ProviderOptions = {
    model?: string
    provider?: "openai" | "ollama"
    config?: OpenAIProviderSettings | OllamaProviderSettings
}

export function getProvider(opt: ProviderOptions) {
    switch (opt.provider) {
        case "openai":
            return createOpenAI(opt.config)
        case "ollama":
            return createOllama(opt.config)
        default:
            throw new Error(`Unsupported provider: ${opt.provider}`)
    }
}
